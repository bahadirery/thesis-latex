This chapter is intended to give the reader an overview of the background knowledge required to understand the rest of the thesis. 
It delves into the foundational concepts of Computer Vision and Deep Learning, elucidating on specific algorithms
and their underlying principles. The importance of reproducibility in scientific research is highlighted, with a particular focus 
on the challenges introduced by randomness in deep learning. This section further dissects the sources of this randomness, 
emphasizing the role of floating-point arithmetic. To provide a practical context, an overview of the datasets, models, and 
the various methods and tools utilized in this research, including optimizers, schedulers, and tracking tools, is presented. 
The aim is to ensure that readers, even those with a peripheral association with the field, can grasp the technical nuances and 
terminologies used throughout the thesis.
\section{Deep Learning}

Deep learning, a subset of machine learning, has established itself as a pinnacle technological advancement. By emulating the human brain through artificial neural networks, it enables machines to learn and make decisions from vast data.

In traditional machine learning, manual feature extraction was crucial. Deep learning automates this process using multi-layered neural networks to extract features from input data. This has led to innovations in image recognition, speech processing, medical diagnosis, and more.

Automation has boosted deep learning's relevance, powering applications in robotics, customer service, self-driving vehicles, and Industry 4.0. It provides efficiency, reliability, and precision surpassing human processes.

Deep learning's impact on Industry 4.0 is profound. In manufacturing, it predicts equipment failures through data from sensors, reducing downtime and enhancing efficiency.

In conclusion, deep learning is pivotal in our data-centric world. From entertainment to critical tasks like medical diagnosis, deep learning's capabilities are indispensable. It's not just an AI trend; it's a stride towards machines that mimic human learning at an unparalleled scale.

\subsection{Deep Learning Essentials}
core concepts of deep learning and explain why we need to mention them in the thesis
\subsubsection{Neural Networks}
what are the neural networks and how do they work
\subsubsection{Backpropagation}
how do neural networks learn
\subsubsection{Activation Functions}
what are activation functions and why they are used
\subsubsection{Loss Functions}
what is the loss
\subsubsection{Optimizers}
what are optimizers and info about the used ones
\subsubsection{Batch Normalization}
why it is standard practice
\subsubsection{Transfer Learning}
what is it and why it is used
\subsubsection{Hyperparameter Tuning}
What does that mean and how it is done
\subsubsection{Performance Metrics}
what are the metrics and how do the specific ones which are used works
\subsubsection{Data Augmentation}
what is data augmentation and why it is used
\subsubsection{Learning Rate Schedulers}
what are learning rate schedulers and why they are used
\subsubsection{Early Stopping}
what is early stopping and why it is used
\subsection{Summarizing Deep Learning Algorithms}
Why there are multiple algorithms and how they are different
\subsubsection{Convolutional Neural Networks}
what are CNNs and advantages of using them
\subsubsection{Transformer Networks}
what are Transformers and advantages of using them and its applications
\subsection{Deep Learning Applications (?)}
what are the applications of deep learning NLP and so on
\section{Computer Vision}
introduction to computer vision
\subsection{Image Classification}
what is image classification and its applications 
\subsection{Applications of Image Classification}
what are the applications of image classification and challenges
\section{Reproducibility in Scientific Research}
introduction to reproducibility
\section{Randomness in Deep Learning}
introduction to randomness
\subsection{Sources of Randomness}
what are the sources of randomness and types of randomness
\subsection{Floating-Point Arithmetics and Parallel Execution}
where does this occur? why it is a source of randomness?
\section{Frameworks and Tools} 
Summary of the tools and frameworks used in Deep learning
\subsection{PyTorch}
The publisher, the community, the advantages, and disadvantages
\subsection{Weights and Biases}
general info about the tracking tools and why it is important to use them
 
